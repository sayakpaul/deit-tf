{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117b6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "904709d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from vit.deit_models import ViTDistilled\n",
    "from vit.model_configs import base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb6af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"deit_distilled_tiny_patch16_224\"\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "NB_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0426f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'token',\n",
       " 'drop_path_rate': 0.1,\n",
       " 'dropout_rate': 0.0,\n",
       " 'image_size': 224,\n",
       " 'init_values': None,\n",
       " 'initializer_range': 0.02,\n",
       " 'input_shape': (224, 224, 3),\n",
       " 'layer_norm_eps': 1e-06,\n",
       " 'mlp_units': [768, 192],\n",
       " 'name': 'deit_distilled_tiny_patch16_224',\n",
       " 'num_classes': 5,\n",
       " 'num_heads': 3,\n",
       " 'num_layers': 12,\n",
       " 'num_patches': 196,\n",
       " 'patch_size': 16,\n",
       " 'pre_logits': False,\n",
       " 'projection_dim': 192}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deit_tiny_config = base_config.get_config(\n",
    "    drop_path_rate=0.1, model_name=MODEL_TYPE\n",
    ")\n",
    "with deit_tiny_config.unlocked():\n",
    "    deit_tiny_config.num_classes = NB_CLASSES\n",
    "\n",
    "deit_tiny_config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a741b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = deit_tiny_config.image_size\n",
    "\n",
    "def preprocess_dataset(is_training=True):\n",
    "    def _pp(image, label):\n",
    "        if is_training:\n",
    "            # Resize to a bigger spatial resolution and take the random\n",
    "            # crops.\n",
    "            image = tf.image.resize(image, (SZ + 20, SZ + 20))\n",
    "            image = tf.image.random_crop(image, (SZ, SZ, 3))\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "        else:\n",
    "            image = tf.image.resize(image, (SZ, SZ))\n",
    "        label = tf.one_hot(label, depth=NB_CLASSES)\n",
    "        return image, label\n",
    "\n",
    "    return _pp\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset, is_training=True):\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(BATCH_SIZE * 10)\n",
    "    dataset = dataset.map(preprocess_dataset(is_training), num_parallel_calls=AUTO)\n",
    "    return dataset.batch(BATCH_SIZE).prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f873ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 3303\n",
      "Number of validation examples: 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 21:23:18.231035: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = tfds.load(\n",
    "    \"tf_flowers\", split=[\"train[:90%]\", \"train[90%:]\"], as_supervised=True\n",
    ")\n",
    "num_train = train_dataset.cardinality()\n",
    "num_val = val_dataset.cardinality()\n",
    "print(f\"Number of training examples: {num_train}\")\n",
    "print(f\"Number of validation examples: {num_val}\")\n",
    "\n",
    "train_dataset = prepare_dataset(train_dataset, is_training=True)\n",
    "val_dataset = prepare_dataset(val_dataset, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df72d8ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m deit_tiny \u001b[38;5;241m=\u001b[39m ViTDistilled(deit_tiny_config)\n\u001b[0;32m----> 3\u001b[0m deit_tiny \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRescaling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeit_tiny\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m resolution \u001b[38;5;241m=\u001b[39m deit_tiny_config\u001b[38;5;241m.\u001b[39mimage_size\n\u001b[1;32m      8\u001b[0m dummy_inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m2\u001b[39m, resolution, resolution, \u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[0;32m~/.local/bin/.virtualenvs/tf-28/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/bin/.virtualenvs/tf-28/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/bin/.virtualenvs/tf-28/lib/python3.8/site-packages/keras/engine/sequential.py:222\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    220\u001b[0m output_tensor \u001b[38;5;241m=\u001b[39m layer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(output_tensor)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 222\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(SINGLE_LAYER_OUTPUT_ERROR_MSG)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs \u001b[38;5;241m=\u001b[39m [output_tensor]\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API."
     ]
    }
   ],
   "source": [
    "deit_tiny = ViTDistilled(deit_tiny_config)\n",
    "\n",
    "deit_tiny = keras.Sequential([keras.Input((SZ, SZ, 3)), keras.layers.Rescaling(scale=1.0 / 255), deit_tiny])\n",
    "\n",
    "resolution = deit_tiny_config.image_size\n",
    "dummy_inputs = tf.ones((2, resolution, resolution, 3))\n",
    "_ = deit_tiny(dummy_inputs)\n",
    "print(f\"Number of parameters (millions): {deit_tiny.count_params() / 1e6}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_teacher_flowers = keras.models.load_model(\"gs://deit-tf/bit_teacher_flowers\")\n",
    "print(f\"Number of parameters (millions): {bit_teacher_flowers.count_params() / 1e6}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcc9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeiT(keras.Model):\n",
    "    def __init__(self, student, teacher, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "    ):\n",
    "        super().compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack data.\n",
    "        x, y = data\n",
    "\n",
    "        # Forward pass of teacher\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student.\n",
    "            cls_predictions, dist_predictions, _ = self.student(x, training=True)\n",
    "\n",
    "            # Compute losses.\n",
    "            student_loss = self.student_loss_fn(y, cls_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                teacher_predictions, dist_predictions\n",
    "            )\n",
    "            loss = (student_loss + distillation_loss) / 2\n",
    "\n",
    "        # Compute gradients.\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights.\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics configured in `compile()`.\n",
    "        student_predictions = (cls_predictions + dist_predictions) / 2\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        # Return a dict of performance.\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data.\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions.\n",
    "        y_prediction, _ = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss.\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance.\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.student(inputs, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f36583a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bit_teacher_flowers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m deit_distiller \u001b[38;5;241m=\u001b[39m DeiT(student\u001b[38;5;241m=\u001b[39mdeit_tiny, teacher\u001b[38;5;241m=\u001b[39m\u001b[43mbit_teacher_flowers\u001b[49m)\n\u001b[1;32m      2\u001b[0m deit_distiller\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(),\n\u001b[1;32m      4\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     distillation_loss_fn\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m _ \u001b[38;5;241m=\u001b[39m deit_distiller\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     11\u001b[0m     train_dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m), validation_data\u001b[38;5;241m=\u001b[39mval_dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bit_teacher_flowers' is not defined"
     ]
    }
   ],
   "source": [
    "deit_distiller = DeiT(student=deit_tiny, teacher=bit_teacher_flowers)\n",
    "deit_distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"],\n",
    "    student_loss_fn=keras.losses.CategoricalCrossentropy(\n",
    "        from_logits=True, label_smoothing=0.1\n",
    "    ),\n",
    "    distillation_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "_ = deit_distiller.fit(\n",
    "    train_dataset.take(1), validation_data=val_dataset.take(1), epochs=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
